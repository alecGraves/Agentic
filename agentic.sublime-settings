{
	// Default values that the user can override
	"default_prompt": "You are an expert programming agent. Focus on correctness and simplicity.",
	"default_models": "models_high",
	"show_reasoning": true,

	"actions": {
		"simplify": {
			"models": "models_high",
			"system": "You are an expert programming agent. Make sure to never negatively impact the correctness or functionality of a program.",
			"prompt": "Analyze this code and simplify it as much as possible to improve conciseness and clarity. Ensure the code works, but please refactor it to be as minimal as possible to ensure performance and clarity."
		},
		"comment": {
			"models": "models_high",
			"system": "You are an expert programming agent. Make sure to carefully analyze the program line-by-line.",
			"prompt": "Restructure and comment key parts of this code to make it more clear and easier to understand and read. Make sure to ensure maximum simplicity."
		},
		"fix": {
			"models": "models_high",
			"system": "You are an expert programming agent. Make sure to carefully analyze the program line-by-line.",
			"prompt": "This code contains a critical logic error that impacts the functionality. Please analyze this code line-by-line for correctness and make a list of any potential issues that you see in each section. Make sure to highlight any glaring mistakes that you can find."
		}
	},

	// These models are good for most programming tasks but can be slow:
	"models_ultra": ["ultra_1"],

	// These models are good for many programming tasks
	"models_high": ["high_1"],

	// These models are for medium tasks
	"models_medium": ["medium_1"],

	// These models are good for small, routine tasks
	"models_low": ["low_1"],

	// List of model configurations
	"models": {
		"ultra_1":
		{
			"url": "http://127.0.0.1:8081/v1/chat/completions",
			"model": "gpt-oss-120b",
			"token": "000000000000",
			"options": {
				"stream": true,  // this is the only thing that works for now
				"reasoning": {"effort":"high"},
				"temperature": 1.0,
				"top_p": 1.0,
				"min_p": 0,
				"top_k": 0
			},
			"context": 131072.0,
			"system": "my_cpu1",
			"workers": 1,
			"speed": 20.0,
			"effort": 32768.0
		},
		"high_1":
		{
			"url": "http://127.0.0.1:8080/v1/chat/completions",
			"model": "gpt-oss-20b",
			"token": "000000000000",
			"options": {
				"stream": true,
				"reasoning": {"effort":"high"},
				"temperature": 1.0,
				"top_p": 1.0,
				"min_p": 0,
				"top_k": 0
			},
			"context": 128000.0,
			"system": "my_gpu1",
			"workers": 3,
			"speed": 120,
			"effort": 32768.0
		},
		"medium_1":
		{
			"url": "http://127.0.0.1:8080/v1/chat/completions",
			"model": "gpt-oss-20b",
			"token": "000000000000",
			"options": {
				"stream": true,
				"reasoning": {"effort":"medium"},
				"temperature": 1.0,
				"top_p": 1.0,
				"min_p": 0,
				"top_k": 0
			},
			"context": 128000.0,
			"system": "my_gpu1",
			"workers": 3,
			"speed": 120,
			"effort": 4096.0
		},
		"low_1":
		{
			"url": "http://127.0.0.1:8080/v1/chat/completions",
			"model": "gpt-oss-20b",
			"token": "000000000000",
			"options": {
				"stream": true,
				"reasoning": {"effort":"low"},
				"temperature": 1.0,
				"top_p": 1.0,
				"min_p": 0,
				"top_k": 0
			},
			"context": 128000.0,
			"system": "my_gpu1",
			"workers": 3,
			"speed": 120,
			"effort": 512.0
		},
	}
}